{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc34b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509182ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\BITTU\\\\OneDrive\\\\ドキュメント\\\\Python Scripts\\\\dataset\\\\breast_cancer.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBITTU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mドキュメント\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPython Scripts\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbreast_cancer.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(file)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\BITTU\\\\OneDrive\\\\ドキュメント\\\\Python Scripts\\\\dataset\\\\breast_cancer.csv'"
     ]
    }
   ],
   "source": [
    "file=(r\"C:\\Users\\BITTU\\OneDrive\\ドキュメント\\Python Scripts\\dataset\\breast_cancer.csv\")\n",
    "df=pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae37f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb64cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b49a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da629490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.describe(),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a677f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15, 10)) meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9bcf4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "The code plt.figure(figsize=(15, 10)) is typically used in the context of data visualization using the matplotlib library in Python. This line of code is setting the size of the figure (the entire plotting area) before creating a plot. Here's a breakdown:\n",
    "\n",
    "plt: This is a common alias for the matplotlib.pyplot module, which provides a MATLAB-like interface for creating plots and visualizations.\n",
    "\n",
    "figure(): This function is used to create a new figure. A figure is the top-level container for all the plot elements.\n",
    "\n",
    "figsize=(15, 10): This parameter sets the size of the figure. It takes a tuple of two values representing the width and height of the figure in inches. In this case, the width is set to 15 inches, and the height is set to 10 inches.\n",
    "\n",
    "So, the code is creating a new figure with a specified size of 15 inches in width and 10 inches in height. This is often done to control the dimensions of the plot and ensure that it is visually appealing and suitable for the intended presentation or analysis. After this line, you can proceed to create and add plots to this figure using other matplotlib functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing boxplot to visualize outlayers\n",
    "plt.figure(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726aaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,2,1)\n",
    "fig=df.boxplot(column=\"Clump Thickness\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Clump Thickness\")\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "fig=df.boxplot(column=\"Uniformity of Cell Size\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Uniformity of Cell Size\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "fig=df.boxplot(column=\"Uniformity of Cell Shape\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Uniformity of Cell Shape\")\n",
    "\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "fig=df.boxplot(column=\"Marginal Adhesion\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Marginal Adhesion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "fig=df.boxplot(column=\"Single Epithelial Cell Size\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Single Epithelial Cell Size\")\n",
    "\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "fig=df.boxplot(column=\"Bare Nuclei\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Bare Nuclei\")\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "fig=df.boxplot(column=\"Bland Chromatin\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Bland Chromatin\")\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "fig=df.boxplot(column=\"Normal Nucleoli\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Normal Nucleoli\")\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "fig=df.boxplot(column=\"Mitoses\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Mitoses\")\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "fig=df.boxplot(column=\"Class\")\n",
    "fig.set_title(\" \")\n",
    "fig.set_ylabel(\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0596c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#values refer to ‘malignant’ = 4 -likely breast cancer or ‘benign’ = 2 - likely not breast cancer.\n",
    "#Let is replace 2 with 0 and 4 with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"].replace(2,0,inplace=True)\n",
    "df[\"Class\"].replace(4,1,inplace=True)\n",
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7942dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "\n",
    "x=df.drop([\"Class\"],axis=1)\n",
    "y=df[\"Class\"]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split x and y into test and training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the dimension for x_train,x_test\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6337fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colums=x_train.columns\n",
    "colums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481e290",
   "metadata": {},
   "source": [
    "Sure, let's simplify the concept of \"fit\" and \"transform\" with an example:\n",
    "\n",
    "Imagine you are a chef, and you want to teach a robot to cook pasta. The robot needs to learn how to cut vegetables and boil water. Here's how the \"fit\" and \"transform\" steps would work:\n",
    "\n",
    "Fit (Learning):\n",
    "\n",
    "Chef's Role: You show the robot how to cut vegetables and explain the process, but you don't actually cut the vegetables for the robot.\n",
    "Machine Learning Analogy: In machine learning, \"fit\" is like teaching the model how to handle the data. It learns the patterns and characteristics of the training data without modifying it.\n",
    "Example: You demonstrate the cutting technique to the robot without actually cutting any vegetables.\n",
    "Transform (Applying What's Learned):\n",
    "\n",
    "Chef's Role: Now, the robot uses the learned cutting technique to actually cut the vegetables.\n",
    "Machine Learning Analogy: \"Transform\" is like applying what the model has learned to new, unseen data. It adapts the knowledge gained during the \"fit\" step to make predictions or preprocess new data.\n",
    "Example: The robot, having learned the cutting technique, now cuts the vegetables on its own.\n",
    "In terms of machine learning code, let's consider the StandardScaler example again:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creating an instance of the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data (learning the parameters)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the learned parameters\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same parameters\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "Fit Step: scaler.fit(X_train) learns the mean and standard deviation from the training data.\n",
    "Transform Step: scaler.transform(X_train) applies the learned mean and standard deviation to standardize the training data. Later, scaler.transform(X_test) applies the same transformation to the testing data, ensuring consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081edf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ee3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(x_train,columns=colums)\n",
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=pd.DataFrame(x_test,columns=colums)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf36b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a logistic regression by using training dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(random_state=0)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16051e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=lr.predict(x_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edbfc8",
   "metadata": {},
   "source": [
    "[:,0] explain easy way with example\n",
    "ChatGPT\n",
    "Sure, let's use a simple example to explain [:, 0]:\n",
    "\n",
    "Imagine you have a table of students with their scores on two exams:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import numpy as np\n",
    "\n",
    "# Create a 2D array representing exam scores\n",
    "exam_scores = np.array([[85, 92],\n",
    "                        [78, 90],\n",
    "                        [88, 89],\n",
    "                        [60, 70]])\n",
    "Each row in this array corresponds to a student, and each column represents a different exam (the first column is Exam 1, and the second column is Exam 2).\n",
    "\n",
    "Now, if you want to get all the scores of the students on Exam 1, you can use [:, 0]:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "exam1_scores = exam_scores[:, 0]\n",
    "Here's the breakdown:\n",
    "\n",
    "[:, 0]:\n",
    ": means \"take all rows.\"\n",
    ", is a separator.\n",
    "0 means \"take the values in the 0th column.\"\n",
    "So, [:, 0] says, \"Give me all the rows, but only the values in the 0th column,\" which, in this case, corresponds to the scores of all students on Exam 1.\n",
    "\n",
    "After running this code, exam1_scores would be [85, 78, 88, 60], representing the scores of all students on Exam 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probablity of getting = 0 in test case\n",
    "lr.predict_proba(x_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ecf577",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90245702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred_test,y_test)\n",
    "print(\"original accuracy :\",accuracy)\n",
    "print(\"rounded accuracy :\",round(accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_test.shape,y_test.shape)\n",
    "print(y_pred_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e94bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the train_set and test_set accuracry\n",
    "#predicting x_train\n",
    "#predicting score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=lr.predict(x_train)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(x_train)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12752df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_pred_train,y_train))\n",
    "print(\"rounded accuracy:\",round(accuracy_score(y_pred_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b940e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test original accuracy :\",accuracy)\n",
    "print(\"test rounded accuracy :\",round(accuracy))\n",
    "\n",
    "print(\"train accuracy:\",accuracy_score(y_pred_train,y_train))\n",
    "print(\"train rounded accuracy:\",round(accuracy_score(y_pred_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find null accuracy score because our predicted score is nearby overfitted.so we now check null accuracy score.\n",
    "#null accuracy=null values/total no.of.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed62d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=107/171\n",
    "print(\"Null accuracy score:\", round(c,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred_test, y_test)\n",
    "\n",
    "print(\"confusion matrix:\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24bbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print(cm)\n",
    "print(\"TP :\",cm[0,0])\n",
    "print(\"TN :\",cm[1,1])\n",
    "print(\"FP :\",cm[0,1])\n",
    "print(\"FN :\",cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=pd.DataFrame(data=cm,columns=[\"ACTUAL:1\",\"ACTUAL:0\"],index=[\"predicted:1\",\"predicted:0\"])\n",
    "sb.heatmap(data=sm,fmt=\"d\",annot=True,cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90115a12",
   "metadata": {},
   "source": [
    "The code snippet you provided is using the classification_report function from scikit-learn's metrics module to generate a text-based summary of classification metrics. Specifically, it prints a classification report comparing the true labels (y_test) with the predicted labels (y_pred_test).\n",
    "\n",
    "Here's a breakdown of what the classification_report provides:\n",
    "\n",
    "Precision: The ratio of correctly predicted positive observations to the total predicted positives. Precision is a measure of how many of the predicted positive instances are actually positive.\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate): The ratio of correctly predicted positive observations to the total actual positives. Recall is a measure of how many of the actual positive instances were predicted correctly.\n",
    "\n",
    "F1-score: The harmonic mean of precision and recall. It's useful when you want to balance precision and recall.\n",
    "\n",
    "Support: The number of actual occurrences of the class in the specified dataset.\n",
    "\n",
    "Accuracy: The proportion of correct predictions among the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr=classification_report(y_test,y_pred_test)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with deifferent threshold frequencies\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "for i in range(1,5):\n",
    "    cm1=0\n",
    "    y_pred1=lr.predict_proba(x_test)[:,1]\n",
    "    threshold=i/10\n",
    "    y_pred2=(y_pred1>threshold).astype(int)\n",
    "    cm1=confusion_matrix(y_test,y_pred2)\n",
    "    \n",
    "    print(\n",
    "        'With',\n",
    "        threshold,\n",
    "        'threshold the Confusion Matrix is ',\n",
    "        '\\n\\n',\n",
    "        cm1,\n",
    "        '\\n\\n',\n",
    "        'with',\n",
    "        cm1[0, 0] + cm1[1, 1],\n",
    "        'correct predictions, ',\n",
    "        '\\n\\n',\n",
    "        cm1[0, 1],\n",
    "        'Type I errors( False Positives), ',\n",
    "        '\\n\\n',\n",
    "        cm1[1, 0],\n",
    "        'Type II errors( False Negatives), ',\n",
    "        '\\n\\n',\n",
    "        'Accuracy score: ',\n",
    "        accuracy_score(y_test, y_pred2),\n",
    "        '\\n\\n',\n",
    "        'Sensitivity: ',\n",
    "        cm1[1, 1] / (float(cm1[1, 1] + cm1[1, 0])),\n",
    "        '\\n\\n',\n",
    "        'Specificity: ',\n",
    "        cm1[0, 0] / (float(cm1[0, 0] + cm1[0, 1])),\n",
    "        '\\n\\n',\n",
    "        '====================================================',\n",
    "        '\\n\\n',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Applying 5-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr, x_train, y_train, cv = 5, scoring='accuracy')\n",
    "\n",
    "scores=scores.mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e7fa9",
   "metadata": {},
   "source": [
    "Comparing with our orginal model score of 0.9708 it has not improved much so we need not apply cross validation\n",
    "\n",
    "So we are satisifed with our logistic regression model and it does a good job for us in predicting breast cancer at a lower threshold of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45553f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr=classification_report(y_pred_train,y_train)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe963a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
